{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Embedding, GlobalMaxPooling1D, Dropout, BatchNormalization, LSTM, GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv(\"CUTe_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>obscene</th>\n",
       "      <th>insulting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"\\n\\nWikipedia an interesting yet frustrating ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"\\n\\nThanks\\nThanks for reverting the vandalis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(UTC)\\n\\nAnd fundamental Christains are not as...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Why don't you go fuck your mom  05:52, 26 Jun ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Not to mention, he's a nobody. He's his bigges...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  hate_speech  \\\n",
       "0   0  \"\\n\\nWikipedia an interesting yet frustrating ...            1   \n",
       "1   1  \"\\n\\nThanks\\nThanks for reverting the vandalis...            0   \n",
       "2   2  (UTC)\\n\\nAnd fundamental Christains are not as...            1   \n",
       "3   3  Why don't you go fuck your mom  05:52, 26 Jun ...            1   \n",
       "4   4  Not to mention, he's a nobody. He's his bigges...            0   \n",
       "\n",
       "   obscene  insulting  \n",
       "0        0          0  \n",
       "1        0          0  \n",
       "2        1          1  \n",
       "3        1          0  \n",
       "4        0          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen  = 300 # Max sequence length of a sentence or row/document.\n",
    "max_features  = 50000 # This picks the top 20,000 most frequent words\n",
    "embedding_dims  = 256\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67252 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# finally, vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(rawdata.text)\n",
    "sequences = tokenizer.texts_to_sequences(rawdata.text)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "# labels = to_categorical(raw.Labels)\n",
    "# print('Shape of data tensor:', data.shape)\n",
    "# print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_validation_samples = int(VALIDATION_SPLIT*data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = data[:-num_validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25308, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = rawdata[[\"hate_speech\",\"obscene\",\"insulting\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>obscene</th>\n",
       "      <th>insulting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hate_speech  obscene  insulting\n",
       "0            1        0          0\n",
       "1            0        0          0\n",
       "2            1        1          1\n",
       "3            1        1          0\n",
       "4            0        0          0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train= data[:-num_validation_samples]\n",
    "x_test= data[-num_validation_samples:]\n",
    "y_train= y[:-num_validation_samples]\n",
    "y_test= y[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25308, 300)\n",
      "(6326, 300)\n",
      "(25308, 3)\n",
      "(6326, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# #embedding_dim = 256\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(max_features, embedding_dims,input_length = maxlen))\n",
    "# model.add(GRU(256, dropout=0.9, return_sequences=True))\n",
    "# model.add(GRU(256, dropout=0.9))\n",
    "# model.add(Dense(3, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "#embedding_dim = 256\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dims,input_length = maxlen))\n",
    "#model.add(GRU(60, dropout=0.9, return_sequences=True))\n",
    "model.add(GRU(60, dropout=0.9))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 256)          12800000  \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 60)                57060     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 183       \n",
      "=================================================================\n",
      "Total params: 12,857,243\n",
      "Trainable params: 12,857,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25308 samples, validate on 6326 samples\n",
      "Epoch 1/5\n",
      "25308/25308 [==============================] - 460s 18ms/step - loss: 0.3864 - acc: 0.8248 - val_loss: 0.2864 - val_acc: 0.8767\n",
      "Epoch 2/5\n",
      "25308/25308 [==============================] - 450s 18ms/step - loss: 0.2610 - acc: 0.8876 - val_loss: 0.2493 - val_acc: 0.8939\n",
      "Epoch 3/5\n",
      "25308/25308 [==============================] - 472s 19ms/step - loss: 0.2277 - acc: 0.9024 - val_loss: 0.2410 - val_acc: 0.8978\n",
      "Epoch 4/5\n",
      "25308/25308 [==============================] - 495s 20ms/step - loss: 0.2087 - acc: 0.9125 - val_loss: 0.2409 - val_acc: 0.8976\n",
      "Epoch 5/5\n",
      "25308/25308 [==============================] - 471s 19ms/step - loss: 0.1935 - acc: 0.9203 - val_loss: 0.2368 - val_acc: 0.8996\n"
     ]
    }
   ],
   "source": [
    "#model.add(GRU(60, dropout=0.9))\n",
    "history = model.fit(x_train, y_train,batch_size=32, epochs=5,  validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25308 samples, validate on 6326 samples\n",
      "Epoch 1/10\n",
      "25308/25308 [==============================] - 667s 26ms/step - loss: 0.4578 - acc: 0.7809 - val_loss: 0.3072 - val_acc: 0.8681\n",
      "Epoch 2/10\n",
      "25308/25308 [==============================] - 653s 26ms/step - loss: 0.3167 - acc: 0.8628 - val_loss: 0.2859 - val_acc: 0.8763\n",
      "Epoch 3/10\n",
      "25308/25308 [==============================] - 649s 26ms/step - loss: 0.2766 - acc: 0.8801 - val_loss: 0.2579 - val_acc: 0.8909\n",
      "Epoch 4/10\n",
      "25308/25308 [==============================] - 649s 26ms/step - loss: 0.2546 - acc: 0.8909 - val_loss: 0.2616 - val_acc: 0.8927\n",
      "Epoch 5/10\n",
      "25308/25308 [==============================] - 648s 26ms/step - loss: 0.2375 - acc: 0.8991 - val_loss: 0.2621 - val_acc: 0.8929\n",
      "Epoch 6/10\n",
      "25308/25308 [==============================] - 644s 25ms/step - loss: 0.2247 - acc: 0.9053 - val_loss: 0.2680 - val_acc: 0.8915\n",
      "Epoch 7/10\n",
      "25308/25308 [==============================] - 645s 25ms/step - loss: 0.2169 - acc: 0.9097 - val_loss: 0.2586 - val_acc: 0.8936\n",
      "Epoch 8/10\n",
      "25308/25308 [==============================] - 643s 25ms/step - loss: 0.2081 - acc: 0.9131 - val_loss: 0.2649 - val_acc: 0.8959\n",
      "Epoch 9/10\n",
      "25308/25308 [==============================] - 643s 25ms/step - loss: 0.1989 - acc: 0.9186 - val_loss: 0.2581 - val_acc: 0.8966\n",
      "Epoch 10/10\n",
      "25308/25308 [==============================] - 648s 26ms/step - loss: 0.1938 - acc: 0.9205 - val_loss: 0.2606 - val_acc: 0.8935\n"
     ]
    }
   ],
   "source": [
    "# model.add(GRU(60, dropout=0.9, return_sequences=True))\n",
    "# model.add(GRU(60, dropout=0.9))\n",
    "history = model.fit(x_train, y_train,batch_size=32, epochs=10,  validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.0432936e-01, 7.2401243e-01, 3.0137855e-01],\n",
       "       [2.5424324e-03, 2.2161102e-03, 4.4957612e-04],\n",
       "       [9.9718106e-01, 9.9041802e-01, 9.2821157e-01],\n",
       "       [4.8439773e-03, 2.0661091e-03, 6.1964733e-04],\n",
       "       [9.3249112e-01, 9.4425030e-02, 2.3853868e-01],\n",
       "       [3.6764280e-03, 1.6733538e-03, 4.6086588e-04],\n",
       "       [2.3389274e-02, 8.4492220e-03, 2.6228488e-03],\n",
       "       [4.1790400e-03, 3.2629196e-03, 5.4730033e-04],\n",
       "       [6.1944812e-03, 6.0694572e-03, 1.0244816e-03]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predicting the values\n",
    "#model.add(GRU(60, dropout=0.9))\n",
    "## Predicting the values\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred[1:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>obscene</th>\n",
       "      <th>insulting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [hate_speech, obscene, insulting]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(columns=['hate_speech','obscene','insulting'])    \n",
    "actualValues = pd.DataFrame(columns=['hate_speech','obscene','insulting']) \n",
    "predictions.head()\n",
    "actualValues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate Speech Recall : 0.908947\n",
      "Obscene Recall : 0.914954\n",
      "Insulting Recall : 0.871641\n",
      "Average Recall : 0.898514\n"
     ]
    }
   ],
   "source": [
    "predictions = pd.DataFrame(columns=['hate_speech','obscene','insulting'])    \n",
    "actualValues = pd.DataFrame(columns=['hate_speech','obscene','insulting']) \n",
    "\n",
    "for i in range(0,len(y_pred)):\n",
    "    currentPrediction = y_pred[i]\n",
    "    hate_speech = 0\n",
    "    obscene = 0\n",
    "    insulting = 0\n",
    "    if(currentPrediction[0] > 0.4):\n",
    "        hate_speech = 1\n",
    "    if(currentPrediction[1] > 0.4):\n",
    "        obscene = 1\n",
    "    if(currentPrediction[2] > 0.4):\n",
    "        insulting = 1\n",
    "    new_row = [hate_speech, obscene, insulting]\n",
    "    #print(new_row)\n",
    "    predictions.loc[i] = new_row\n",
    "\n",
    "y_test_np = y_test.values\n",
    "for i in range(0,len(y_test_np)):\n",
    "    new_row = [y_test_np[i][0],y_test_np[i][1],y_test_np[i][2]]\n",
    "    actualValues.loc[i] = new_row\n",
    "\t\n",
    "predictions[['hate_speech','obscene','insulting']] = predictions[['hate_speech','obscene','insulting']].astype(int)\n",
    "actualValues[['hate_speech','obscene','insulting']] = actualValues[['hate_speech','obscene','insulting']].astype(int)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "hate_speech_rc = recall_score(predictions['hate_speech'], actualValues['hate_speech'], average='weighted')\n",
    "obscene_rc = recall_score(predictions['obscene'], actualValues['obscene'], average='weighted')\n",
    "insulting_rc = recall_score(predictions['insulting'], actualValues['insulting'], average='weighted')\n",
    "print(\"Hate Speech Recall : %f\" %(hate_speech_rc))\n",
    "print(\"Obscene Recall : %f\" %(obscene_rc))  \n",
    "print(\"Insulting Recall : %f\" %(insulting_rc))\n",
    "print(\"Average Recall : %f\" %((hate_speech_rc + obscene_rc + insulting_rc)/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Count of class hate_speech in actual data: 3088\n",
      "Count of class obscene in actual data: 1765\n",
      "Count of class insulting in actual data: 1521\n",
      "Count of class hate_speech in predictions data: 3226\n",
      "Count of class obscene in predictions data: 1925\n",
      "Count of class insulting in predictions data: 1677\n",
      "2869\n",
      "1576\n",
      "1193\n",
      "Hate_Speech Fraction: 0.509959\n",
      "Obscene Fraction: 0.304300\n",
      "Insulting Fraction: 0.265096\n"
     ]
    }
   ],
   "source": [
    "# Manually calculating recall\n",
    "print(type(predictions))\n",
    "print(type(actualValues))\n",
    "\n",
    "# Print the unique classes and their counts/frequencies in actual test_data\n",
    "print(\"Count of class hate_speech in actual data: %d\" %sum(actualValues['hate_speech']))\n",
    "print(\"Count of class obscene in actual data: %d\" %sum(actualValues['obscene']))\n",
    "print(\"Count of class insulting in actual data: %d\" %sum(actualValues['insulting']))\n",
    "\n",
    "# Print the unique classes and their counts/frequencies in actual test_data\n",
    "print(\"Count of class hate_speech in predictions data: %d\" %sum(predictions['hate_speech']))\n",
    "print(\"Count of class obscene in predictions data: %d\" %sum(predictions['obscene']))\n",
    "print(\"Count of class insulting in predictions data: %d\" %sum(predictions['insulting']))\n",
    "\n",
    "TP_hate_speech = sum(predictions['hate_speech']*actualValues['hate_speech'])\n",
    "print(TP_hate_speech)\n",
    "TP_obscene = sum(predictions['obscene']*actualValues['obscene'])\n",
    "print(TP_obscene)\n",
    "TP_insulting = sum(predictions['insulting']*actualValues['insulting'])\n",
    "print(TP_insulting)\n",
    "\n",
    "# Calculating individual recall\n",
    "recall_hate_speech = TP_hate_speech / sum(actualValues['hate_speech'])\n",
    "recall_obscene = TP_obscene / sum(actualValues['obscene'])\n",
    "recall_insulting = TP_insulting / sum(actualValues['insulting'])\n",
    "\n",
    "fraction_hate_speech = sum(predictions['hate_speech'])/len(y_test)\n",
    "fraction_obscene = sum(predictions['obscene'])/len(y_test)\n",
    "fraction_insulting = sum(predictions['insulting'])/len(y_test)\n",
    "\n",
    "# Print individual class fractions\n",
    "print(\"Hate_Speech Fraction: %f\" %fraction_hate_speech)\n",
    "print(\"Obscene Fraction: %f\" %fraction_obscene)\n",
    "print(\"Insulting Fraction: %f\" %fraction_insulting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate_Speech Recall: 0.929080\n",
      "Obscene Recall: 0.892918\n",
      "Insulting Recall: 0.784352\n",
      "Weighted Recall: 0.883339\n"
     ]
    }
   ],
   "source": [
    "# Print individual recalls\n",
    "print(\"Hate_Speech Recall: %f\" %(recall_hate_speech))\n",
    "print(\"Obscene Recall: %f\" %(recall_obscene))  \n",
    "print(\"Insulting Recall: %f\" %(recall_insulting))\n",
    "\n",
    "recall_weighted = (fraction_hate_speech*recall_hate_speech + fraction_obscene*recall_obscene + fraction_insulting*recall_insulting) / (fraction_hate_speech + fraction_obscene + fraction_insulting)\n",
    "print(\"Weighted Recall: %f\" %(recall_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
