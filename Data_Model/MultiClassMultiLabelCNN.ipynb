{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Embedding, GlobalMaxPooling1D, Dropout, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv(\"CUTe_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>obscene</th>\n",
       "      <th>insulting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"\\n\\nWikipedia an interesting yet frustrating ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"\\n\\nThanks\\nThanks for reverting the vandalis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(UTC)\\n\\nAnd fundamental Christains are not as...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Why don't you go fuck your mom  05:52, 26 Jun ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Not to mention, he's a nobody. He's his bigges...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  hate_speech  \\\n",
       "0   0  \"\\n\\nWikipedia an interesting yet frustrating ...            1   \n",
       "1   1  \"\\n\\nThanks\\nThanks for reverting the vandalis...            0   \n",
       "2   2  (UTC)\\n\\nAnd fundamental Christains are not as...            1   \n",
       "3   3  Why don't you go fuck your mom  05:52, 26 Jun ...            1   \n",
       "4   4  Not to mention, he's a nobody. He's his bigges...            0   \n",
       "\n",
       "   obscene  insulting  \n",
       "0        0          0  \n",
       "1        0          0  \n",
       "2        1          1  \n",
       "3        1          0  \n",
       "4        0          0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen  = 300 # Max sequence length of a sentence or row/document.\n",
    "max_features  = 20000 # This picks the top 20,000 most frequent words\n",
    "embedding_dims  = 60\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67252 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# finally, vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(rawdata.text)\n",
    "sequences = tokenizer.texts_to_sequences(rawdata.text)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "# labels = to_categorical(raw.Labels)\n",
    "# print('Shape of data tensor:', data.shape)\n",
    "# print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_validation_samples = int(VALIDATION_SPLIT*data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = data[:-num_validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25308, 300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = rawdata[[\"hate_speech\",\"obscene\",\"insulting\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>obscene</th>\n",
       "      <th>insulting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hate_speech  obscene  insulting\n",
       "0            1        0          0\n",
       "1            0        0          0\n",
       "2            1        1          1\n",
       "3            1        1          0\n",
       "4            0        0          0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train= data[:-num_validation_samples]\n",
    "x_test= data[-num_validation_samples:]\n",
    "y_train= y[:-num_validation_samples]\n",
    "y_test= y[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25308, 300)\n",
      "(6326, 300)\n",
      "(25308, 3)\n",
      "(6326, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_input = Input((maxlen,))\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "X = Embedding(max_features, embedding_dims, input_length=maxlen)(sequence_input)\n",
    "#                         embeddings_initializer=\"uniform\")(comment_input)\n",
    "\n",
    "X = Conv1D(64, 5, activation='relu')(X)\n",
    "\n",
    "# we add a GlobalMaxPooling1D, which will extract features from the embeddings\n",
    "# of all words in the comment\n",
    "h = GlobalMaxPooling1D()(X)\n",
    "\n",
    "comment_emb = Dropout(0.1)(h)\n",
    "comment_emb= Dense(50, activation=\"relu\")(comment_emb)\n",
    "comment_emb = Dropout(0.1)(comment_emb)\n",
    "\n",
    "# We project onto a six-unit output layer, and squash it with a sigmoid:\n",
    "output = Dense(3, activation='sigmoid')(h)\n",
    "\n",
    "model = Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 300, 200)          4000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 296, 64)           64064     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 4,064,259\n",
      "Trainable params: 4,064,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25308 samples, validate on 6326 samples\n",
      "Epoch 1/2\n",
      "25308/25308 [==============================] - 202s 8ms/step - loss: 0.3151 - acc: 0.8685 - val_loss: 0.2979 - val_acc: 0.8762\n",
      "Epoch 2/2\n",
      "25308/25308 [==============================] - 211s 8ms/step - loss: 0.2312 - acc: 0.9089 - val_loss: 0.3163 - val_acc: 0.8778\n"
     ]
    }
   ],
   "source": [
    "model_hist = model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=2,\n",
    "              validation_data=(x_test, y_test)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU, BatchNormalization\n",
    "\n",
    "sequence_input = Input((maxlen,))\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "X = Embedding(max_features, embedding_dims, input_length=maxlen)(sequence_input)\n",
    "#                         embeddings_initializer=\"uniform\")(comment_input)\n",
    "\n",
    "X = Conv1D(64, 5,  activation='linear')(X)\n",
    "X = LeakyReLU(alpha=0.1)(X)\n",
    "# we add a GlobalMaxPooling1D, which will extract features from the embeddings\n",
    "# of all words in the comment\n",
    "h = GlobalMaxPooling1D()(X)\n",
    "\n",
    "comment_emb = Dropout(0.1)(h)\n",
    "#comment_emb = BatchNormalization()(comment_emb)\n",
    "\n",
    "comment_emb= Dense(50, activation='linear')(comment_emb)\n",
    "comment_emb = LeakyReLU(alpha=0.1)(comment_emb)\n",
    "comment_emb = Dropout(0.1)(comment_emb)\n",
    "#comment_emb = BatchNormalization()(comment_emb)\n",
    "\n",
    "# We project onto a six-unit output layer, and squash it with a sigmoid:\n",
    "output = Dense(3, activation='sigmoid')(h)\n",
    "\n",
    "model = Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25308 samples, validate on 6326 samples\n",
      "Epoch 1/10\n",
      "25308/25308 [==============================] - 95s 4ms/step - loss: 0.1650 - acc: 0.9364 - val_loss: 0.3668 - val_acc: 0.8737\n",
      "Epoch 2/10\n",
      "25308/25308 [==============================] - 98s 4ms/step - loss: 0.1280 - acc: 0.9541 - val_loss: 0.4087 - val_acc: 0.8762\n",
      "Epoch 3/10\n",
      "25308/25308 [==============================] - 94s 4ms/step - loss: 0.1010 - acc: 0.9664 - val_loss: 0.4824 - val_acc: 0.8744\n",
      "Epoch 4/10\n",
      "25308/25308 [==============================] - 84s 3ms/step - loss: 0.0867 - acc: 0.9726 - val_loss: 0.5391 - val_acc: 0.8734\n",
      "Epoch 5/10\n",
      "25308/25308 [==============================] - 85s 3ms/step - loss: 0.0832 - acc: 0.9753 - val_loss: 0.5911 - val_acc: 0.8745\n",
      "Epoch 6/10\n",
      "25308/25308 [==============================] - 94s 4ms/step - loss: 0.0752 - acc: 0.9784 - val_loss: 0.7038 - val_acc: 0.8768\n",
      "Epoch 7/10\n",
      "25308/25308 [==============================] - 96s 4ms/step - loss: 0.0761 - acc: 0.9791 - val_loss: 0.7665 - val_acc: 0.8699\n",
      "Epoch 8/10\n",
      "25308/25308 [==============================] - 94s 4ms/step - loss: 0.0756 - acc: 0.9807 - val_loss: 0.8468 - val_acc: 0.8629\n",
      "Epoch 9/10\n",
      "25308/25308 [==============================] - 97s 4ms/step - loss: 0.0664 - acc: 0.9831 - val_loss: 0.9511 - val_acc: 0.8684\n",
      "Epoch 10/10\n",
      "25308/25308 [==============================] - 89s 4ms/step - loss: 0.0696 - acc: 0.9832 - val_loss: 1.0034 - val_acc: 0.8643\n"
     ]
    }
   ],
   "source": [
    "#droput 0.1\n",
    "model_hist = model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=10,\n",
    "              validation_data=(x_test, y_test)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
